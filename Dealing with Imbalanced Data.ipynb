{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with Imbalanced Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imbalanced classes are a common problem in machine learning classification where there are a disproportionate ratio of observations in each class. \n",
    "\n",
    "We'll look at a few possible ways to handle imbalanced class problem using credit card data. We want to correctly classify the minority class of fraudulent transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 31)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    284315\n",
      "1       492\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.Class.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0, 'Not Fraud'), Text(0, 0, 'Fraud')]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEGCAYAAACpXNjrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAU40lEQVR4nO3dfdDdZX3n8ffHBHyoD6AESglrWJvulNIaIQXUtuvDLARmdwMudKBWsixrHAfWh3E7xc50YUW2tltKiyBbLJGHcY2sSKEtbswgK3VU5EazPOqQUlYiLASDQFdxDX73j3PdyyE5uXMnXOfcJHm/Zs6c3/n+rt/1u34zBz737+FcSVUhSVJPL5rrAUiSdj+GiySpO8NFktSd4SJJ6s5wkSR1N3+uB/BCsd9++9WiRYvmehiStEu5/fbbH6uqBVvWDZdm0aJFTE1NzfUwJGmXkuR/jap7WUyS1J3hIknqznCRJHVnuEiSujNcJEndGS6SpO4MF0lSd4aLJKk7w0WS1J2/0O/o199z3lwPQS9Af/vnvz/XQ5AmzjMXSVJ3hoskqTvDRZLUneEiSerOcJEkdWe4SJK6M1wkSd0ZLpKk7gwXSVJ3hoskqTvDRZLUneEiSerOcJEkdWe4SJK6M1wkSd0ZLpKk7gwXSVJ3hoskqTvDRZLUneEiSerOcJEkdTe2cElycJKbk9yb5O4k72/1c5N8L8m69jp+aJsPJ1mf5DtJjh2qL2u19UnOHqofkuTWJPcl+WySvVv9xe3z+rZ+0biOU5K0tXGeuWwGPlRVvwgcDZyZ5NC27sKqWtJeNwK0dacAvwQsAz6RZF6SecAlwHHAocCpQ/38YetrMfA4cEarnwE8XlU/D1zY2kmSJmRs4VJVD1fVN9vyU8C9wEEzbLIcWF1VP66qvwfWA0e21/qqur+q/i+wGlieJMDbgM+17a8EThjq68q2/Dng7a29JGkCJnLPpV2WegNwayudleSOJKuS7NtqBwEPDm22odW2VX8N8IOq2rxF/Tl9tfVPtPZbjmtlkqkkUxs3bnxexyhJetbYwyXJy4FrgQ9U1ZPApcDrgCXAw8AF001HbF47UZ+pr+cWqi6rqqVVtXTBggUzHockafbGGi5J9mIQLJ+uqs8DVNUjVfVMVf0U+CSDy14wOPM4eGjzhcBDM9QfA/ZJMn+L+nP6autfBWzqe3SSpG0Z59NiAS4H7q2qPxmqHzjU7ETgrrZ8A3BKe9LrEGAx8A3gNmBxezJsbwY3/W+oqgJuBk5q268Arh/qa0VbPgn4UmsvSZqA+dtvstPeDLwLuDPJulb7PQZPey1hcJnqAeA9AFV1d5JrgHsYPGl2ZlU9A5DkLGANMA9YVVV3t/5+F1id5KPAtxiEGe396iTrGZyxnDLG45QkbWFs4VJVX2H0vY8bZ9jmfOD8EfUbR21XVffz7GW14frTwMk7Ml5JUj/+Ql+S1J3hIknqznCRJHVnuEiSujNcJEndGS6SpO4MF0lSd4aLJKk7w0WS1J3hIknqznCRJHVnuEiSujNcJEndGS6SpO4MF0lSd4aLJKk7w0WS1J3hIknqznCRJHVnuEiSujNcJEndGS6SpO4MF0lSd4aLJKk7w0WS1J3hIknqznCRJHU3tnBJcnCSm5Pcm+TuJO9v9VcnWZvkvva+b6snyUVJ1ie5I8nhQ32taO3vS7JiqH5EkjvbNhclyUz7kCRNxjjPXDYDH6qqXwSOBs5McihwNnBTVS0GbmqfAY4DFrfXSuBSGAQFcA5wFHAkcM5QWFza2k5vt6zVt7UPSdIEjC1cqurhqvpmW34KuBc4CFgOXNmaXQmc0JaXA1fVwNeBfZIcCBwLrK2qTVX1OLAWWNbWvbKqvlZVBVy1RV+j9iFJmoCJ3HNJsgh4A3ArcEBVPQyDAAL2b80OAh4c2mxDq81U3zCizgz72HJcK5NMJZnauHHjzh6eJGkLYw+XJC8HrgU+UFVPztR0RK12oj5rVXVZVS2tqqULFizYkU0lSTMYa7gk2YtBsHy6qj7fyo+0S1q090dbfQNw8NDmC4GHtlNfOKI+0z4kSRMwzqfFAlwO3FtVfzK06gZg+omvFcD1Q/XT2lNjRwNPtEtaa4BjkuzbbuQfA6xp655KcnTb12lb9DVqH5KkCZg/xr7fDLwLuDPJulb7PeBjwDVJzgC+C5zc1t0IHA+sB34InA5QVZuSnAfc1tp9pKo2teX3AlcALwW+0F7MsA9J0gSMLVyq6iuMvi8C8PYR7Qs4cxt9rQJWjahPAYeNqH9/1D4kSZPhL/QlSd0ZLpKk7gwXSVJ3hoskqTvDRZLUneEiSerOcJEkdWe4SJK6M1wkSd0ZLpKk7gwXSVJ3hoskqTvDRZLUneEiSerOcJEkdWe4SJK6M1wkSd0ZLpKk7gwXSVJ3hoskqbtZhUuSm2ZTkyQJYP5MK5O8BHgZsF+SfYG0Va8Efm7MY5Mk7aJmDBfgPcAHGATJ7TwbLk8Cl4xxXJKkXdiM4VJVfwb8WZJ/V1Ufn9CYJEm7uO2duQBQVR9P8iZg0fA2VXXVmMYlSdqFzSpcklwNvA5YBzzTygUYLpKkrcwqXIClwKFVVeMcjCRp9zDb37ncBfzsjnScZFWSR5PcNVQ7N8n3kqxrr+OH1n04yfok30ly7FB9WautT3L2UP2QJLcmuS/JZ5Ps3eovbp/Xt/WLdmTckqTnb7bhsh9wT5I1SW6Yfm1nmyuAZSPqF1bVkva6ESDJocApwC+1bT6RZF6SeQyeSjsOOBQ4tbUF+MPW12LgceCMVj8DeLyqfh64sLWTJE3QbC+LnbujHVfVLTtw1rAcWF1VPwb+Psl64Mi2bn1V3Q+QZDWwPMm9wNuA32ptrmxjvLT1NT3ezwEXJ4mX9CRpcmb7tNiXO+7zrCSnAVPAh6rqceAg4OtDbTa0GsCDW9SPAl4D/KCqNo9of9D0NlW1OckTrf1jHY9BkjSD2U7/8lSSJ9vr6STPJHlyJ/Z3KYOnzpYADwMXTO9iRNvaifpMfW0lycokU0mmNm7cONO4JUk7YFbhUlWvqKpXttdLgH8FXLyjO6uqR6rqmar6KfBJnr30tQE4eKjpQuChGeqPAfskmb9F/Tl9tfWvAjZtYzyXVdXSqlq6YMGCHT0cSdI27NSsyFX1lwzueeyQJAcOfTyRwVNoADcAp7QnvQ4BFgPfAG4DFrcnw/ZmcNP/hnb/5GbgpLb9CuD6ob5WtOWTgC95v0WSJmu2P6J8x9DHFzH43cuM/8NO8hngLQwmvdwAnAO8JcmStu0DDOYuo6ruTnINcA+wGTizqp5p/ZwFrAHmAauq6u62i98FVif5KPAt4PJWvxy4uj0UsIlBIEmSJmi2T4v9i6HlzQyCYflMG1TVqSPKl4+oTbc/Hzh/RP1G4MYR9ft59rLacP1p4OSZxiZJGq/ZPi12+rgHIknafcz2abGFSa5rv7h/JMm1SRaOe3CSpF3TbG/of4rBjfKfY/A7kr9qNUmStjLbcFlQVZ+qqs3tdQXgs7uSpJFmGy6PJfnt6fm+kvw28P1xDkyStOuabbj8G+A3gf/N4Jf1JwHe5JckjTTbR5HPA1a0ecBI8mrgjxmEjiRJzzHbM5dfmQ4WgKraBLxhPEOSJO3qZhsuL0qy7/SHduYy27MeSdIeZrYBcQHw1SSfYzB1y28y4tf0kiTB7H+hf1WSKQaTVQZ4R1XdM9aRSZJ2WbO+tNXCxECRJG3XTk25L0nSTAwXSVJ3hoskqTvDRZLUneEiSerOcJEkdWe4SJK6M1wkSd0ZLpKk7gwXSVJ3hoskqTvDRZLUneEiSerOcJEkdWe4SJK6M1wkSd2NLVySrEryaJK7hmqvTrI2yX3tfd9WT5KLkqxPckeSw4e2WdHa35dkxVD9iCR3tm0uSpKZ9iFJmpxxnrlcASzbonY2cFNVLQZuap8BjgMWt9dK4FIYBAVwDnAUcCRwzlBYXNraTm+3bDv7kCRNyNjCpapuATZtUV4OXNmWrwROGKpfVQNfB/ZJciBwLLC2qjZV1ePAWmBZW/fKqvpaVRVw1RZ9jdqHJGlCJn3P5YCqehigve/f6gcBDw6129BqM9U3jKjPtI+tJFmZZCrJ1MaNG3f6oCRJz/VCuaGfEbXaifoOqarLqmppVS1dsGDBjm4uSdqGSYfLI+2SFu390VbfABw81G4h8NB26gtH1GfahyRpQiYdLjcA0098rQCuH6qf1p4aOxp4ol3SWgMck2TfdiP/GGBNW/dUkqPbU2KnbdHXqH1IkiZk/rg6TvIZ4C3Afkk2MHjq62PANUnOAL4LnNya3wgcD6wHfgicDlBVm5KcB9zW2n2kqqYfEngvgyfSXgp8ob2YYR+SpAkZW7hU1anbWPX2EW0LOHMb/awCVo2oTwGHjah/f9Q+JEmT80K5oS9J2o0YLpKk7gwXSVJ3hoskqTvDRZLUneEiSerOcJEkdWe4SJK6M1wkSd0ZLpKk7gwXSVJ3hoskqTvDRZLUneEiSerOcJEkdWe4SJK6M1wkSd0ZLpKk7gwXSVJ3hoskqTvDRZLUneEiSerOcJEkdWe4SJK6M1wkSd0ZLpKk7gwXSVJ3cxIuSR5IcmeSdUmmWu3VSdYmua+979vqSXJRkvVJ7khy+FA/K1r7+5KsGKof0fpf37bN5I9SkvZcc3nm8taqWlJVS9vns4GbqmoxcFP7DHAcsLi9VgKXwiCMgHOAo4AjgXOmA6m1WTm03bLxH44kadoL6bLYcuDKtnwlcMJQ/aoa+DqwT5IDgWOBtVW1qaoeB9YCy9q6V1bV16qqgKuG+pIkTcBchUsBX0xye5KVrXZAVT0M0N73b/WDgAeHtt3QajPVN4yobyXJyiRTSaY2btz4PA9JkjRt/hzt981V9VCS/YG1Sb49Q9tR90tqJ+pbF6suAy4DWLp06cg2kqQdNydnLlX1UHt/FLiOwT2TR9olLdr7o635BuDgoc0XAg9tp75wRF2SNCETD5ckP5PkFdPLwDHAXcANwPQTXyuA69vyDcBp7amxo4En2mWzNcAxSfZtN/KPAda0dU8lObo9JXbaUF+SpAmYi8tiBwDXtaeD5wP/tar+e5LbgGuSnAF8Fzi5tb8ROB5YD/wQOB2gqjYlOQ+4rbX7SFVtasvvBa4AXgp8ob0kSRMy8XCpqvuB14+ofx94+4h6AWduo69VwKoR9SngsOc9WEnSTnkhPYosSdpNGC6SpO4MF0lSd4aLJKk7w0WS1J3hIknqznCRJHVnuEiSujNcJEndGS6SpO4MF0lSd4aLJKk7w0WS1J3hIknqznCRJHVnuEiSujNcJEndGS6SpO4MF0lSd4aLJKk7w0WS1J3hIknqznCRJHVnuEiSujNcJEndGS6SpO4MF0lSd4aLJKm73TZckixL8p0k65OcPdfjkaQ9yW4ZLknmAZcAxwGHAqcmOXRuRyVJe475cz2AMTkSWF9V9wMkWQ0sB+6Z01FJc+SY1R+e6yHoBeiLp/zB2PpOVY2t87mS5CRgWVX92/b5XcBRVXXWFu1WAivbx38CfGeiA9297Qc8NteDkEbwu9nXa6tqwZbF3fXMJSNqW6VoVV0GXDb+4ex5kkxV1dK5Hoe0Jb+bk7Fb3nMBNgAHD31eCDw0R2ORpD3O7houtwGLkxySZG/gFOCGOR6TJO0xdsvLYlW1OclZwBpgHrCqqu6e42HtabzcqBcqv5sTsFve0Jckza3d9bKYJGkOGS6SpO4Mlz1UkkpywdDnf5/k3O1sc8K2ZjpIcm6S7yVZ114f6zzk6f1c0X7HJJHkmaHv3Loki8awj0VJ7urd7+5ut7yhr1n5MfCOJH9QVbP9QdkJwF+z7ZkOLqyqP97WxknmVdUzOzhOaSY/qqol21qZZH5VbZ7kgDTgmcueazODp2Y+uOWKJK9NclOSO9r7P0ryJuBfAv+5/YX4utnsJMkDSf5Dkq8AJyd5d5LbkvzPJNcmeVlr95wzkiT/0N6T5OIk9yT5G2D/53/o2p0l+ddJ/luSvwK+mOTl7Xv8zSR3Jlne2j3njGT47D3JEe07+jXgzDk5kF2c4bJnuwR4Z5JXbVG/GLiqqn4F+DRwUVV9lcFvhX6nqpZU1d+N6O+DQ5cnjh2qP11Vv1ZVq4HPV9WvVtXrgXuBM7YzxhMZTM3zy8C7gTft8FFqd/bSoe/cdUP1NwIrquptwNPAiVV1OPBW4IIko2bxGPYp4H1V9cbxDHv352WxPVhVPZnkKuB9wI+GVr0ReEdbvhr4o1l2ua3LYp8dWj4syUeBfYCXM/gt0kx+A/hMu5z2UJIvzXIs2jNs67LY2qra1JYD/KckvwH8FDgIOGBbHbY/tvapqi+30tUMZljXDvDMRX/K4OzhZ2Zo83x/DPV/hpavAM6qql8G/iPwklbfTPs+tr8q9+64f+15hr9z7wQWAEe0IHqEwffu/3/nmunvYvA797wZLnu49tfdNTz38tRXGUyZA4P/ML/Slp8CXvE8d/kK4OEke7W+pz0AHNGWlwN7teVbgFOSzEtyIIPLGtKOeBXwaFX9JMlbgde2+iPA/klek+TFwD8HqKofAE8k+bXW7p1b9ajtMlwEcAGDacinvQ84PckdwLuA97f6auB3knxrtjf0R/h94FZgLfDtofongX+a5BvAUTz7l+d1wH3AncClwJeRdsyngaVJphgExbcBquonwEcYfB//mud+H08HLmk39H+EdpjTv0iSuvPMRZLUneEiSerOcJEkdWe4SJK6M1wkSd0ZLtIcSPKzSVYn+bs2b9qNSX7B2Xe1u3D6F2nC2gwE1wFXVtUprbaEGaYkkXY1nrlIk/dW4CdV9V+mC1W1Dnhw+nObsfdv20y+32yzUpPkwCS3tIka70ry6232giva5zuTbDXTtTRpnrlIk3cYcPt22jwK/LOqejrJYuAzwFLgt4A1VXV+knnAy4AlwEFVdRhAkn3GN3RpdgwX6YVpL+DidrnsGeAXWv02YFWbm+0vq2pdkvuBf5zk48DfAF+ckxFLQ7wsJk3e3Tw7See2fJDBxIqvZ3DGsjdAVd3C4J8h+B5wdZLTqurx1u5/MPiHrf5iPMOWZs9wkSbvS8CLk7x7upDkV3l2tl4YzOT7cFX9lMHkofNau9cymOH3k8DlwOFJ9gNeVFXXMpgY9PDJHIa0bV4WkyasqirJicCfJjmbwb+U+ADwgaFmnwCuTXIycDPPzhL9FgYzU/8E+AfgNAb/+NWnkkz/sfjhsR+EtB3OiixJ6s7LYpKk7gwXSVJ3hoskqTvDRZLUneEiSerOcJEkdWe4SJK6+3/dDPdOWN0hXwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "g = sns.countplot(df.Class,palette='viridis')\n",
    "g.set_xticklabels(['Not Fraud', 'Fraud'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17304750013189596"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(df.loc[df.Class==1])) / (len(df.loc[df.Class == 0])) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot above we can see how skewed the distributions are. Our target class accounts for only 0.17% of our dataset. This dataset is highly imbalanced with something like 99.8% of the transactions being not fraudulent. \n",
    "We should look at the confusion matrix and see how many of the fraudulent transactions we are actually able to identify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Class', axis = 1)\n",
    "y = df.Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver='liblinear').fit(X_train, y_train)\n",
    "lr_prediction = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9988828242203709"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, lr_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    93869\n",
       "1      118\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pd.DataFrame(lr_prediction)\n",
    "predictions[0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Logistic Regression, we can predict that there are 118 instances of class 1. This is good but can we do better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Change the performance metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is not the best metric to use when evaluating imbalanced datasets as it can be misleading. Metrics that can provide better insight include:\n",
    "\n",
    "Confusion Matrix: a table showing correct predictions and types of incorrect predictions.\n",
    "\n",
    "Precision: the number of true positives divided by all positive predictions. \n",
    "Precision is also called Positive Predictive Value. It is a measure of a classifier's exactness. Low precision indicates a high number of false positives.\n",
    "\n",
    "Recall: the number of true positives divided by the number of positive values in the test data. Recall is also called Sensitivity or the True Positive Rate. It is a measure of a classifier's completeness. Low recall indicates a high number of false negatives.\n",
    "\n",
    "F1: Score: the weighted average of precision and recall.\n",
    "Since our main objective with the dataset is to prioritize accuraltely classifying fraud cases the recall score can be considered our main metric to use for evaluating outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6181818181818182"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f1 score\n",
    "\n",
    "f1_score(y_test, lr_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>93797</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0   1\n",
       "0  93797  33\n",
       "1     72  85"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_test, lr_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5414012738853503"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, lr_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a very high accuracy score of 0.998 but a F1 score of only 0.618. And from the confusion matrix, we can see we are misclassifying several observations leading to a recall score of only 0.54."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Change the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is always a good idea to try a variety of algorithims when dealing with imbalanced datasets. Decision trees frequently perform well on imbalanced data. They work by learning a hierachy of if/else questions. This can force both classes to be addressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999521210380159"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=10).fit(X_train, y_train)\n",
    "\n",
    "# predict on test set\n",
    "\n",
    "rfc_prediction = rfc.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, rfc_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8398576512455517"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#f1 score\n",
    "\n",
    "f1_score(y_test, rfc_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>93824</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1\n",
       "0  93824    6\n",
       "1     39  118"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_test, rfc_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7515923566878981"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#recall score\n",
    "\n",
    "recall_score(y_test, rfc_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Oversampling Minority Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oversampling can be defined as adding more copies of the minority class. Oversampling can be a good choice when you don't have a ton of data to work with. A possible drawback to consider when undersampling is that it can cause overfitting and poor generalization to your test set.\n",
    "\n",
    "We will use the resampling module from Scikit-Learn to randomly replicate samples from the minority class.\n",
    "\n",
    "It is important we always split into test and train sets before any resampling techniques. Oversampling before splitting the data can allow the exact same observations to be present in both the test and train sets! Our model will then simply memorise specific data points and cause overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate input features and target\n",
    "\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df.Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up testing and training sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50093</td>\n",
       "      <td>44343.0</td>\n",
       "      <td>-0.512045</td>\n",
       "      <td>0.903785</td>\n",
       "      <td>1.564528</td>\n",
       "      <td>1.400223</td>\n",
       "      <td>0.037308</td>\n",
       "      <td>-0.182233</td>\n",
       "      <td>0.552689</td>\n",
       "      <td>0.122513</td>\n",
       "      <td>-0.231995</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007402</td>\n",
       "      <td>0.279788</td>\n",
       "      <td>-0.068434</td>\n",
       "      <td>0.408627</td>\n",
       "      <td>-0.144738</td>\n",
       "      <td>-0.242263</td>\n",
       "      <td>0.420430</td>\n",
       "      <td>0.208938</td>\n",
       "      <td>17.34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198744</td>\n",
       "      <td>132631.0</td>\n",
       "      <td>-1.013748</td>\n",
       "      <td>-0.296800</td>\n",
       "      <td>1.672464</td>\n",
       "      <td>-0.157600</td>\n",
       "      <td>-0.005596</td>\n",
       "      <td>0.183444</td>\n",
       "      <td>0.378501</td>\n",
       "      <td>-0.605630</td>\n",
       "      <td>0.679077</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016647</td>\n",
       "      <td>0.715653</td>\n",
       "      <td>-0.658018</td>\n",
       "      <td>0.822073</td>\n",
       "      <td>0.013633</td>\n",
       "      <td>1.168677</td>\n",
       "      <td>-0.460515</td>\n",
       "      <td>-0.337174</td>\n",
       "      <td>139.40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35358</td>\n",
       "      <td>38085.0</td>\n",
       "      <td>-5.278534</td>\n",
       "      <td>2.184014</td>\n",
       "      <td>-1.870685</td>\n",
       "      <td>-2.642741</td>\n",
       "      <td>-3.416694</td>\n",
       "      <td>1.361060</td>\n",
       "      <td>-3.969136</td>\n",
       "      <td>4.375162</td>\n",
       "      <td>-3.116073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.501476</td>\n",
       "      <td>0.599292</td>\n",
       "      <td>0.067674</td>\n",
       "      <td>-1.366679</td>\n",
       "      <td>0.306418</td>\n",
       "      <td>-0.098684</td>\n",
       "      <td>-1.346567</td>\n",
       "      <td>-0.399267</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174063</td>\n",
       "      <td>121750.0</td>\n",
       "      <td>2.019981</td>\n",
       "      <td>-0.889599</td>\n",
       "      <td>-1.076011</td>\n",
       "      <td>-0.626016</td>\n",
       "      <td>0.041409</td>\n",
       "      <td>1.068362</td>\n",
       "      <td>-0.839940</td>\n",
       "      <td>0.250268</td>\n",
       "      <td>-0.327486</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.166844</td>\n",
       "      <td>0.275689</td>\n",
       "      <td>0.316024</td>\n",
       "      <td>-0.307216</td>\n",
       "      <td>-0.413173</td>\n",
       "      <td>0.754892</td>\n",
       "      <td>0.015831</td>\n",
       "      <td>-0.058720</td>\n",
       "      <td>13.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181587</td>\n",
       "      <td>125037.0</td>\n",
       "      <td>0.448903</td>\n",
       "      <td>-0.175230</td>\n",
       "      <td>0.606674</td>\n",
       "      <td>-1.876915</td>\n",
       "      <td>0.012498</td>\n",
       "      <td>-0.370099</td>\n",
       "      <td>0.287547</td>\n",
       "      <td>-0.316988</td>\n",
       "      <td>-0.688054</td>\n",
       "      <td>...</td>\n",
       "      <td>0.221677</td>\n",
       "      <td>0.791562</td>\n",
       "      <td>-0.047682</td>\n",
       "      <td>0.698088</td>\n",
       "      <td>-0.311208</td>\n",
       "      <td>-0.312486</td>\n",
       "      <td>-0.132074</td>\n",
       "      <td>-0.214401</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "50093    44343.0 -0.512045  0.903785  1.564528  1.400223  0.037308 -0.182233   \n",
       "198744  132631.0 -1.013748 -0.296800  1.672464 -0.157600 -0.005596  0.183444   \n",
       "35358    38085.0 -5.278534  2.184014 -1.870685 -2.642741 -3.416694  1.361060   \n",
       "174063  121750.0  2.019981 -0.889599 -1.076011 -0.626016  0.041409  1.068362   \n",
       "181587  125037.0  0.448903 -0.175230  0.606674 -1.876915  0.012498 -0.370099   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "50093   0.552689  0.122513 -0.231995  ... -0.007402  0.279788 -0.068434   \n",
       "198744  0.378501 -0.605630  0.679077  ... -0.016647  0.715653 -0.658018   \n",
       "35358  -3.969136  4.375162 -3.116073  ...  0.501476  0.599292  0.067674   \n",
       "174063 -0.839940  0.250268 -0.327486  ... -0.166844  0.275689  0.316024   \n",
       "181587  0.287547 -0.316988 -0.688054  ...  0.221677  0.791562 -0.047682   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "50093   0.408627 -0.144738 -0.242263  0.420430  0.208938   17.34      0  \n",
       "198744  0.822073  0.013633  1.168677 -0.460515 -0.337174  139.40      0  \n",
       "35358  -1.366679  0.306418 -0.098684 -1.346567 -0.399267   25.00      0  \n",
       "174063 -0.307216 -0.413173  0.754892  0.015831 -0.058720   13.00      0  \n",
       "181587  0.698088 -0.311208 -0.312486 -0.132074 -0.214401   25.00      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate our training data back together\n",
    "\n",
    "X = pd.concat([X_train, y_train], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate minority and majority classes\n",
    "\n",
    "not_fraud = X[X.Class==0]\n",
    "fraud = X[X.Class==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsample minority\n",
    "\n",
    "fraud_upsampled = resample(fraud,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(not_fraud), # match number in majority class\n",
    "                          random_state=27) # reproducible results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine majority and upsampled minority\n",
    "\n",
    "upsampled = pd.concat([not_fraud, fraud_upsampled])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    190485\n",
       "0    190485\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check new class counts\n",
    "\n",
    "upsampled.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying logistic regression again with the balanced dataset\n",
    "\n",
    "y_train = upsampled.Class\n",
    "X_train = upsampled.drop('Class', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsampled = LogisticRegression(solver='liblinear').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsampled_pred = upsampled.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9766882653984061"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking accuracy\n",
    "accuracy_score(y_test, upsampled_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11403154063890011"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f1 score\n",
    "f1_score(y_test, upsampled_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>91655</td>\n",
       "      <td>2175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1\n",
       "0  91655  2175\n",
       "1     16   141"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "pd.DataFrame(confusion_matrix(y_test, upsampled_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8980891719745223"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, upsampled_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our accuracy score decreased after upsampling, but the model is now predicting both classes more equally, making it an improvement over our plain logistic regression above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Undersampling Majority Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undersampling can be defined as removing some observations of the majority class. Undersampling can be a good choice when you have a ton of data -think millions of rows. But a drawback to undersampling is that we are removing information that may be valuable.\n",
    "\n",
    "We will again use the resampling module from Scikit-Learn to randomly remove samples from the majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    335\n",
       "0    335\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# still using our separated classes fraud and not_fraud from above\n",
    "\n",
    "# downsample majority\n",
    "\n",
    "not_fraud_downsampled = resample(not_fraud,\n",
    "                                replace = False, # sample without replacement\n",
    "                                n_samples = len(fraud), # match minority n\n",
    "                                random_state = 27) # reproducible results\n",
    "\n",
    "# combine minority and downsampled majority\n",
    "\n",
    "downsampled = pd.concat([not_fraud_downsampled, fraud])\n",
    "\n",
    "# checking counts\n",
    "\n",
    "downsampled.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying logistic regression again with the undersampled dataset\n",
    "\n",
    "y_train = downsampled.Class\n",
    "X_train = downsampled.drop('Class', axis=1)\n",
    "\n",
    "undersampled = LogisticRegression(solver='liblinear').fit(X_train, y_train)\n",
    "\n",
    "undersampled_pred = undersampled.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9703788821858342"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking accuracy\n",
    "\n",
    "accuracy_score(y_test, undersampled_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09197651663405089"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f1 score\n",
    "\n",
    "f1_score(y_test, undersampled_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>91062</td>\n",
       "      <td>2768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1\n",
       "0  91062  2768\n",
       "1     16   141"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_test, undersampled_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8980891719745223"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, undersampled_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undersampling produced a higher recall score than oversampling. It is worth noting, however, that we used a small number of total samples in training the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have covered a few methods for dealing with imbalanced datasets:\n",
    "\n",
    "1. Change the performance metric\n",
    "2. Change the algorithim\n",
    "3. Oversampling the minority class\n",
    "4. Undersampling the majority class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are just some of the many possible methods to try when dealing with imbalanced datasets, and not an exhaustive list. Some others methods to consider are collecting more data or choosing different resampling ratios - you don't have to have exactly a 1:1 ratio! You should always try several approaches and then decide which is best for your problem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
